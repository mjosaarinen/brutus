// wbob_pi64sl.c
// 11-Jun-14  Markku-Juhani O. Saarinen <mjos@iki.fi>

// 64-bit bitsliced WhirlBob Pi

#include "stribob.h"

#ifndef ROTL64
#define ROTL64(x, y) (((x) << (y)) | ((x) >> (64 - (y))))
#endif

// These miniboxes are direcly lifted from Appendix B of the WhirlPool spec

#define SLICE_SEF(z0, z1, z2, z3, u0, u1, u2, u3) { \
    t0 = u0 & u2;   \
    t0 = t0 ^ u1;   \
    t2 = ~u0;       \
    t1 = u3 ^ t2;   \
    t2 = t0 | t1;   \
    z0 = u0 ^ t2;   \
    t2 = u2 & t0;   \
    t1 = t1 ^ t2;   \
    t2 = u3 | z0;   \
    z1 = t2 ^ t1;   \
    t2 = u2 ^ t1;   \
    t1 = t1 ^ u3;   \
    t0 = t0 ^ t2;   \
    t1 = t1 | t0;   \
    z2 = t2 ^ t1;   \
    t1 = z1 & z2;   \
    t1 = t1 | z0;   \
    z3 = t0 ^ t1; }

#define SLICE_SEI(z0, z1, z2, z3, u0, u1, u2, u3) { \
    t0 = ~u0;       \
    t1 = u0 | u1;   \
    t1 = t1 ^ u3;   \
    t2 = u2 & t1;   \
    z3 = t0 ^ t2;   \
    t2 = u0 & u2;   \
    t3 = u0 | u3;   \
    t3 = t3 ^ t2;   \
    t3 = t3 & u1;   \
    z0 = t0 ^ t3;   \
    t2 = t2 ^ u1;   \
    t3 = u2 ^ t0;   \
    t4 = z3 ^ t2;   \
    t1 = t1 & t4;   \
    t2 = t2 | t1;   \
    z2 = t3 ^ t1;   \
    t0 = t0 | u3;   \
    z1 = t0 ^ t2; }

#define SLICE_SRF(z0, z1, z2, z3, u0, u1, u2, u3) { \
    t0 = ~u0;       \
    t1 = u2 & u3;   \
    t2 = u0 ^ t1;   \
    t2 = t2 | u1;   \
    t3 = u3 | t0;   \
    z2 = t2 ^ t3;   \
    t2 = ~u2;       \
    t2 = t2 ^ t3;   \
    t3 = u1 | t2;   \
    z3 = t1 ^ t3;   \
    t3 = t3 ^ t0;   \
    t0 = u0 | z3;   \
    t1 = ~u1;   \
    t1 = t1 ^ u3;   \
    z0 = t0 ^ t1;   \
    t3 = t3 | z0;   \
    z1 = t2 ^ t3; }

// ShiftColumns

#define SLICE_SHC(z) {                      \
    z = (0x00FF00FF00FF00FF & z) |          \
        (0xFE00FE00FE00FE00 & (z << 1)) |   \
        (0x0100010001000100 & (z >> 7));    \
    z = (0x0000FFFF0000FFFF & z) |          \
        (0xFCFC0000FCFC0000 & (z << 2)) |   \
        (0x0303000003030000 & (z >> 6));    \
    z = (0x00000000FFFFFFFF & z) |          \
        (0xF0F0F0F000000000 & (z << 4)) |   \
        (0x0F0F0F0F00000000 & (z >> 4)); }

// MixRows (MDS)

#define SLICE_MDS(z0, z1, z2, z3, z4, z5, z6, z7,                       \
                    u0, u1, u2, u3, u4, u5, u6, u7) {                   \
    z0 = u0;                                                            \
    t0 = ROTL64(u0, 8); z0 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z2 = t0;                                        \
    t0 = ROTL64(t0, 8); z0 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z3 = t0;                                        \
    t0 = ROTL64(t0, 8); z0 ^= t0;   z2 ^= t0;                           \
    t0 = ROTL64(t0, 8); z1 = t0;                                        \
    t0 = ROTL64(t0, 8); z0 ^= t0;   z3 ^= t0;                           \
    z1 ^= u1;                                                           \
    t0 = ROTL64(u1, 8); z1 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z3 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z1 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z4 = t0;                                        \
    t0 = ROTL64(t0, 8); z1 ^= t0;   z3 ^= t0;                           \
    t0 = ROTL64(t0, 8); z2 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z1 ^= t0;   z4 ^= t0;                           \
    z2 ^= u2;                                                           \
    t0 = ROTL64(u2, 8); z2 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z4 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z2 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z5 = t0;                                        \
    t0 = ROTL64(t0, 8); z2 ^= t0;   z4 ^= t0;                           \
    t0 = ROTL64(t0, 8); z3 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z2 ^= t0;   z5 ^= t0;                           \
    z3 ^= u3;                                                           \
    t0 = ROTL64(u3, 8); z3 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z5 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z3 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z6 = t0;                                        \
    t0 = ROTL64(t0, 8); z3 ^= t0;   z5 ^= t0;                           \
    t0 = ROTL64(t0, 8); z4 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z3 ^= t0;   z6 ^= t0;                           \
    z4 ^= u4;                                                           \
    t0 = ROTL64(u4, 8); z4 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z6 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z4 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z7 = t0;                                        \
    t0 = ROTL64(t0, 8); z4 ^= t0;   z6 ^= t0;                           \
    t0 = ROTL64(t0, 8); z5 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z4 ^= t0;   z7 ^= t0;                           \
    z5 ^= u5;                                                           \
    t0 = ROTL64(u5, 8); z5 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z7 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z5 ^= t0;                                       \
    t0 = ROTL64(t0, 8); t1 = t0;                                        \
    t0 = ROTL64(t0, 8); z5 ^= t0;   z7 ^= t0;                           \
    t0 = ROTL64(t0, 8); z6 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z5 ^= t0;                                       \
    t1 ^= t0;           z0 ^= t1;   z2 ^= t1;   z3 ^= t1;   z4 ^= t1;   \
    z6 ^= u6;                                                           \
    t0 = ROTL64(u6, 8); z6 ^= t0;                                       \
    t0 = ROTL64(t0, 8); t1 = t0;                                        \
    t0 = ROTL64(t0, 8); z6 ^= t0;                                       \
    t0 = ROTL64(t0, 8); t2 = t0;                                        \
    t0 = ROTL64(t0, 8); z6 ^= t0;                                       \
    t1 ^= t0;           z0 ^= t1;   z2 ^= t1;   z3 ^= t1;   z4 ^= t1;   \
    t0 = ROTL64(t0, 8); z7 ^= t0;                                       \
    t0 = ROTL64(t0, 8); z6 ^= t0;                                       \
    t2 ^= t0;           z1 ^= t2;   z3 ^= t2;   z4 ^= t2;   z5 ^= t2;   \
    z7 ^= u7;                                                           \
    t0 = ROTL64(u7, 8); z7 ^= t0;                                       \
    t0 = ROTL64(t0, 8); t1 = t0;                                        \
    t0 = ROTL64(t0, 8); z7 ^= t0;                                       \
    t0 = ROTL64(t0, 8); t2 = t0;                                        \
    t0 = ROTL64(t0, 8); z7 ^= t0;                                       \
    t1 ^= t0;           z1 ^= t1;   z3 ^= t1;   z4 ^= t1;   z5 ^= t1;   \
    t0 = ROTL64(t0, 8); z0 ^= t0;   z2 ^= t0;   z3 ^= t0;   z4 ^= t0;   \
    t0 = ROTL64(t0, 8); z7 ^= t0;                                       \
    t2 ^= t0;           z2 ^= t2;   z4 ^= t2;   z5 ^= t2;   z6 ^= t2; }

// a 8x64 byte-oriented bitslicer. this is an involution (self-inverse)

#define SPLICE_8X64(r0, r1, r2, r3, r4, r5, r6, r7, \
                    s0, s1, s2, s3, s4, s5, s6, s7) { \
    r0 =    ((s0 & 0x0101010101010101)     ) |  \
            ((s1 & 0x0101010101010101) << 1) |  \
            ((s2 & 0x0101010101010101) << 2) |  \
            ((s3 & 0x0101010101010101) << 3) |  \
            ((s4 & 0x0101010101010101) << 4) |  \
            ((s5 & 0x0101010101010101) << 5) |  \
            ((s6 & 0x0101010101010101) << 6) |  \
            ((s7 & 0x0101010101010101) << 7);   \
    r1 =    ((s0 & 0x0202020202020202) >> 1) |  \
            ((s1 & 0x0202020202020202)     ) |  \
            ((s2 & 0x0202020202020202) << 1) |  \
            ((s3 & 0x0202020202020202) << 2) |  \
            ((s4 & 0x0202020202020202) << 3) |  \
            ((s5 & 0x0202020202020202) << 4) |  \
            ((s6 & 0x0202020202020202) << 5) |  \
            ((s7 & 0x0202020202020202) << 6);   \
    r2 =    ((s0 & 0x0404040404040404) >> 2) |  \
            ((s1 & 0x0404040404040404) >> 1) |  \
            ((s2 & 0x0404040404040404)     ) |  \
            ((s3 & 0x0404040404040404) << 1) |  \
            ((s4 & 0x0404040404040404) << 2) |  \
            ((s5 & 0x0404040404040404) << 3) |  \
            ((s6 & 0x0404040404040404) << 4) |  \
            ((s7 & 0x0404040404040404) << 5);   \
    r3 =    ((s0 & 0x0808080808080808) >> 3) |  \
            ((s1 & 0x0808080808080808) >> 2) |  \
            ((s2 & 0x0808080808080808) >> 1) |  \
            ((s3 & 0x0808080808080808)     ) |  \
            ((s4 & 0x0808080808080808) << 1) |  \
            ((s5 & 0x0808080808080808) << 2) |  \
            ((s6 & 0x0808080808080808) << 3) |  \
            ((s7 & 0x0808080808080808) << 4);   \
    r4 =    ((s0 & 0x1010101010101010) >> 4) |  \
            ((s1 & 0x1010101010101010) >> 3) |  \
            ((s2 & 0x1010101010101010) >> 2) |  \
            ((s3 & 0x1010101010101010) >> 1) |  \
            ((s4 & 0x1010101010101010)     ) |  \
            ((s5 & 0x1010101010101010) << 1) |  \
            ((s6 & 0x1010101010101010) << 2) |  \
            ((s7 & 0x1010101010101010) << 3);   \
    r5 =    ((s0 & 0x2020202020202020) >> 5) |  \
            ((s1 & 0x2020202020202020) >> 4) |  \
            ((s2 & 0x2020202020202020) >> 3) |  \
            ((s3 & 0x2020202020202020) >> 2) |  \
            ((s4 & 0x2020202020202020) >> 1) |  \
            ((s5 & 0x2020202020202020)     ) |  \
            ((s6 & 0x2020202020202020) << 1) |  \
            ((s7 & 0x2020202020202020) << 2);   \
    r6 =    ((s0 & 0x4040404040404040) >> 6) |  \
            ((s1 & 0x4040404040404040) >> 5) |  \
            ((s2 & 0x4040404040404040) >> 4) |  \
            ((s3 & 0x4040404040404040) >> 3) |  \
            ((s4 & 0x4040404040404040) >> 2) |  \
            ((s5 & 0x4040404040404040) >> 1) |  \
            ((s6 & 0x4040404040404040)     ) |  \
            ((s7 & 0x4040404040404040) << 1);   \
    r7 =    ((s0 & 0x8080808080808080) >> 7) |  \
            ((s1 & 0x8080808080808080) >> 6) |  \
            ((s2 & 0x8080808080808080) >> 5) |  \
            ((s3 & 0x8080808080808080) >> 4) |  \
            ((s4 & 0x8080808080808080) >> 3) |  \
            ((s5 & 0x8080808080808080) >> 2) |  \
            ((s6 & 0x8080808080808080) >> 1) |  \
            ((s7 & 0x8080808080808080)     ); }

// Round Constants

static const uint64_t wbob_slice_rc[12][8] = {
    { 0x0101000100000100, 0x0100000100010100,
      0x0100000100010000, 0x0100010001000001,
      0x0000010000000001, 0x0000010001000100,
      0x0100000001010000, 0x0000010101010000 },
    { 0x0001010101000000, 0x0100010000010101,
      0x0000010001000101, 0x0000010100000000,
      0x0101000101010001, 0x0000010101000101,
      0x0100010101010000, 0x0001000001010100 },
    { 0x0101000100010000, 0x0001000101010000,
      0x0100010001000100, 0x0001010001010100,
      0x0101000000010100, 0x0101000100000101,
      0x0001000000000001, 0x0000000101010100 },
    { 0x0100010000010001, 0x0101010101010000,
      0x0101000100010001, 0x0001010100000001,
      0x0101000000010001, 0x0001000100000100,
      0x0101010001010100, 0x0001000001010100 },
    { 0x0000000101010101, 0x0101000100010100,
      0x0000000101010101, 0x0101000100000000,
      0x0100010100010101, 0x0000010001010100,
      0x0101010001000100, 0x0100010101000000 },
    { 0x0101000100010100, 0x0001000001000000,
      0x0100000000000000, 0x0001000001010101,
      0x0000000100000001, 0x0001010100010000,
      0x0001000000000101, 0x0100010100000100 },
    { 0x0101000100000101, 0x0100010100000000,
      0x0101010001000101, 0x0000010100000101,
      0x0000010001010101, 0x0100010001000001,
      0x0100000101000100, 0x0000000101000001 },
    { 0x0001010101010100, 0x0000000101000100,
      0x0001010100000101, 0x0100010001000000,
      0x0101010000000000, 0x0000010100000101,
      0x0100010000010001, 0x0101000101000001 },
    { 0x0001010100000001, 0x0101010001000101,
      0x0101010101010100, 0x0100000100010101,
      0x0100010100010001, 0x0000000001010101,
      0x0001000101010101, 0x0100000100000101 },
    { 0x0101000101010100, 0x0101010001010001,
      0x0000000101010100, 0x0000010100010101,
      0x0100010000010000, 0x0100000100010100,
      0x0000010000000001, 0x0001000100010001 },
    { 0x0101010001000001, 0x0000000000010101,
      0x0000000000000000, 0x0101010100010000,
      0x0100010001000000, 0x0000000001010001,
      0x0101000101000001, 0x0100000100010000 },
    { 0x0000000000010100, 0x0001010100010101,
      0x0000010000000000, 0x0000000101010000,
      0x0101000100010001, 0x0101010000000101,
      0x0000000000010101, 0x0100000101000101 }
};

void wbob_pi(w512_t *s512)
{
    int r;
    uint64_t *p;
    uint64_t z0, z1, z2, z3, z4, z5, z6, z7,
             u0, u1, u2, u3, u4, u5, u6, u7,
             v0, v1, v2, v3, w0, w1, w2, w3,
             t0, t1, t2, t3, t4;

    p = (uint64_t *) s512;

    SPLICE_8X64(u0, u1, u2, u3, u4, u5, u6, u7,
                p[0], p[1], p[2], p[3], p[4], p[5], p[6], p[7]);

    for (r = 0; r < 12; r++) {

        // SubBytes
        SLICE_SEI(z0, z1, z2, z3, u0, u1, u2, u3);
        SLICE_SEF(z4, z5, z6, z7, u4, u5, u6, u7);
        v0 = z0 ^ z4;
        v1 = z1 ^ z5;
        v2 = z2 ^ z6;
        v3 = z3 ^ z7;
        SLICE_SRF(w0, w1, w2, w3, v0, v1, v2, v3);
        z0 = z0 ^ w0;
        z1 = z1 ^ w1;
        z2 = z2 ^ w2;
        z3 = z3 ^ w3;
        z4 = z4 ^ w0;
        z5 = z5 ^ w1;
        z6 = z6 ^ w2;
        z7 = z7 ^ w3;
        SLICE_SEI(v0, v1, v2, v3, z0, z1, z2, z3);
        SLICE_SEF(w0, w1, w2, w3, z4, z5, z6, z7);

        // ShiftColumns
        SLICE_SHC(v0);
        SLICE_SHC(v1);
        SLICE_SHC(v2);
        SLICE_SHC(v3);
        SLICE_SHC(w0);
        SLICE_SHC(w1);
        SLICE_SHC(w2);
        SLICE_SHC(w3);

        // MixRows
        SLICE_MDS(u0, u1, u2, u3, u4, u5, u6, u7,
            v0, v1, v2, v3, w0, w1, w2, w3);

        // AddRoundKey
        u0 ^= wbob_slice_rc[r][0];
        u1 ^= wbob_slice_rc[r][1];
        u2 ^= wbob_slice_rc[r][2];
        u3 ^= wbob_slice_rc[r][3];
        u4 ^= wbob_slice_rc[r][4];
        u5 ^= wbob_slice_rc[r][5];
        u6 ^= wbob_slice_rc[r][6];
        u7 ^= wbob_slice_rc[r][7];
    }

    SPLICE_8X64(p[0], p[1], p[2], p[3], p[4], p[5], p[6], p[7],
                u0, u1, u2, u3, u4, u5, u6, u7 );
}

